{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base parser (Part 2 - Upload annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (Customizable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jdc\n",
    "\n",
    "from dtlpylidar.parser_base import extrinsic_calibrations\n",
    "from dtlpylidar.parser_base import images_and_pcds, camera_calibrations, lidar_frame, lidar_scene\n",
    "import dtlpylidar.utilities.transformations as transformations\n",
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "logger = logging.Logger(name=\"lidar_base_parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataloop dataset and remote path (On the Dataloop dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the target Dataloop dataset to build the lidar scene for, with the path to the folder where the lidar scene files are located in the target Dataloop dataset.\n",
    "`Note:` This time we will need the `frames.json` item to upload the annotations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"\"  # TODO: fill with dataset id\n",
    "dataset = dl.datasets.get(dataset_id=dataset_id)\n",
    "remote_path: str = \"/\"\n",
    "item_id = \"\"  # TODO: fill with frames.json item id\n",
    "frames_item = dl.items.get(item_id=item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:` This time we will use this method to download the annotation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LidarBaseParser(dl.BaseServiceRunner):\n",
    "    @staticmethod\n",
    "    def download_data(dataset: dl.Dataset, remote_path: str, download_path: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Download the required data for the parser\n",
    "        :param dataset: Input dataset\n",
    "        :param remote_path: Path to the remote folder where the lidar data is uploaded\n",
    "        :param download_path: Path to the downloaded data\n",
    "        :return: (items_path, json_path) Paths to the downloaded items and annotations JSON files directories\n",
    "        \"\"\"\n",
    "        # Download items dataloop annotation JSONs\n",
    "        # (PCD and Image annotation JSONs contains the Dataloop platform references (Like: ID) to the remote files)\n",
    "        filters = dl.Filters(field=\"metadata.system.mimetype\", values=\"*pcd*\", method=dl.FiltersMethod.OR)\n",
    "        filters.add(field=\"metadata.system.mimetype\", values=\"*image*\", method=dl.FiltersMethod.OR)\n",
    "        dataset.download_annotations(local_path=download_path, filters=filters)\n",
    "\n",
    "        # Download required binaries (Calibrations Data)\n",
    "        # Pandaset Calibration Data is saved in JSON files (Like: poses.json, intrinsics.json, timestamps.json)\n",
    "        filters = dl.Filters(field=\"metadata.system.mimetype\", values=\"*json*\")\n",
    "        dataset.items.download(local_path=download_path, filters=filters)\n",
    "\n",
    "        # Download required binaries (Annotations Data)\n",
    "        # Pandaset Annotations Data is saved in CSV files (Like: 01.csv in cuboids folder)\n",
    "        filters = dl.Filters(field=\"metadata.system.mimetype\", values=\"*csv*\")\n",
    "        dataset.items.download(local_path=download_path, filters=filters)\n",
    "\n",
    "        items_path = os.path.join(download_path, \"items\", remote_path)\n",
    "        json_path = os.path.join(download_path, \"json\", remote_path)\n",
    "        return items_path, json_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run to download annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LidarBaseParser()\n",
    "\n",
    "if remote_path.startswith(\"/\"):\n",
    "    remote_path = remote_path[1:]\n",
    "\n",
    "if remote_path.endswith(\"/\"):\n",
    "    remote_path = remote_path[:-1]\n",
    "\n",
    "download_path = os.path.join(os.getcwd(), dataset.name)\n",
    "\n",
    "items_path, json_path = parser.download_data(\n",
    "    dataset=dataset,\n",
    "    remote_path=remote_path,\n",
    "    download_path=download_path,\n",
    ")\n",
    "print(items_path + \"\\n\" + json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse annotations (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to parse the annotations data from all the downloaded files. \\\n",
    "`Notices:`\n",
    "\n",
    "1. It is possible to modify the function to upload 3D annotations to the 3D point cloud files and 2D annotations to the images.\n",
    "\n",
    "2. Annotations uploaded to the separated point cloud and images files will not be visible on the frames.json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to LidarBaseParser\n",
    "@staticmethod\n",
    "def parse_annotations(frames_item: dl.Item, items_path: str, json_path: str):\n",
    "    \"\"\"\n",
    "    Parse the annotations data to build and upload the annotations to the frames.json item\n",
    "    :param items_path: Paths to the downloaded items directory\n",
    "    :param json_path: Paths to the downloaded annotations JSON files directory\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # annotations_json_path = os.path.join(json_path, \"annotations\")\n",
    "    annotations_items_path = os.path.join(items_path, \"annotations\")\n",
    "\n",
    "    builder = frames_item.annotations.builder()\n",
    "    frames_json_data = json.loads(s=frames_item.download(save_locally=False).getvalue())\n",
    "\n",
    "    next_object_id = 0\n",
    "    uid_to_object_id_map = dict()\n",
    "    labels = set()\n",
    "\n",
    "    # Parse the cuboid annotations and add them to the annotations builder\n",
    "    cuboids_items_path = os.path.join(annotations_items_path, \"cuboids\")\n",
    "    cuboids_csvs = pathlib.Path(cuboids_items_path).rglob('*.csv')\n",
    "    cuboids_csvs = sorted(cuboids_csvs, key=lambda x: int(x.stem))\n",
    "\n",
    "    for csv_frame_idx, cuboids_csv in enumerate(cuboids_csvs):\n",
    "        # Getting the lidar scene frame Translation and Rotation\n",
    "        frame_pcd_translation = frames_json_data[\"frames\"][csv_frame_idx][\"translation\"]\n",
    "        frame_pcd_translation = np.array(\n",
    "            [frame_pcd_translation[\"x\"], frame_pcd_translation[\"y\"], frame_pcd_translation[\"z\"]]\n",
    "        )\n",
    "        frame_pcd_rotation = frames_json_data[\"frames\"][csv_frame_idx][\"rotation\"]\n",
    "        frame_pcd_rotation = np.array(\n",
    "            [frame_pcd_rotation[\"x\"], frame_pcd_rotation[\"y\"], frame_pcd_rotation[\"z\"], frame_pcd_rotation[\"w\"]]\n",
    "        )\n",
    "\n",
    "        # Opening the current scene frame, cuboid annotations CSV file to get the cuboids annotation data\n",
    "        cuboids_csv_data = pd.read_csv(filepath_or_buffer=cuboids_csv)\n",
    "        for _, row_data in cuboids_csv_data.iterrows():\n",
    "            object_id = uid_to_object_id_map.get(row_data[\"uuid\"], None)\n",
    "            if object_id is None:\n",
    "                object_id = next_object_id\n",
    "                uid_to_object_id_map[row_data[\"uuid\"]] = object_id\n",
    "                next_object_id += 1\n",
    "\n",
    "            ann_label = row_data[\"label\"]\n",
    "            ann_position = np.array([row_data[\"position.x\"], row_data[\"position.y\"], row_data[\"position.z\"]])\n",
    "            ann_quaternion = transformations.quaternion_from_euler(*[0, 0, row_data[\"yaw\"]])\n",
    "            ann_scale = np.array([row_data[\"dimensions.x\"], row_data[\"dimensions.y\"], row_data[\"dimensions.z\"]])\n",
    "\n",
    "            # Calculate the transform matrix of the cuboid annotation relatively to the Scene Frame\n",
    "            ann_transform_matrix = transformations.calc_cuboid_scene_transform_matrix(\n",
    "                cuboid_position=ann_position,\n",
    "                cuboid_quaternion=ann_quaternion,\n",
    "                cuboid_scale=ann_scale,\n",
    "                scene_position=frame_pcd_translation,\n",
    "                scene_quaternion=frame_pcd_rotation\n",
    "            )\n",
    "\n",
    "            # Extract the cuboid Translation and Rotation from the transform matrix\n",
    "            ann_position = transformations.translation_vector_from_transform_matrix(\n",
    "                transform_matrix=ann_transform_matrix\n",
    "            )\n",
    "            ann_rotation_matrix = transformations.rotation_matrix_from_transform_matrix(\n",
    "                transform_matrix=ann_transform_matrix\n",
    "            )\n",
    "            ann_rotation = transformations.euler_from_rotation_matrix(rotation_matrix=ann_rotation_matrix)\n",
    "\n",
    "            # Add the cuboid annotation to the annotations builder\n",
    "            annotation_definition = dl.Cube3d(\n",
    "                label=ann_label,\n",
    "                position=ann_position,\n",
    "                scale=ann_scale,\n",
    "                rotation=ann_rotation\n",
    "            )\n",
    "            builder.add(\n",
    "                annotation_definition=annotation_definition,\n",
    "                object_id=object_id,\n",
    "                frame_num=csv_frame_idx\n",
    "            )\n",
    "            labels.add(ann_label)\n",
    "\n",
    "    builder.upload()\n",
    "    frames_item.dataset.update_labels(label_list=list(labels), upsert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LidarBaseParser()\n",
    "\n",
    "parser.parse_annotations(frames_item=frames_item, items_path=items_path, json_path=json_path)\n",
    "# frames_item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the directory with all the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(path=download_path, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
