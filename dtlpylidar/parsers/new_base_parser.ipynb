{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook provides a converter for setting up a lidar scene for the Dataloop Platform (In this example for: [Pandaset](https://www.kaggle.com/datasets/usharengaraju/pandaset-dataset)), and it can be extended to support Custom Lidar Scenes by updating the following available `Customizable` methods as needed.\n",
    "\n",
    "`Notice:` The converter assumes that the remove dataset have the Pandaset `.ply` files converted to either `.pcd` files (for the point cloud files) or  `.csv` files for the annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required libraries to to parse the Lidar Scene Data. Add more libraries as needed for custom scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from dtlpylidar.parser_base import extrinsic_calibrations\n",
    "from dtlpylidar.parser_base import images_and_pcds, camera_calibrations, lidar_frame, lidar_scene\n",
    "import dtlpylidar.utilities.transformations as transformations\n",
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "logger = logging.Logger(name=\"lidar_base_parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataloop Dataset and Remote Path (On the Dataloop Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the target Dataloop Dataset to build the lidar scene for, with the path to the folder where the lidar scene files are located in the target Dataloop Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_id = \"\"\n",
    "dataset = dl.datasets.get(dataset_id=dataset_id)\n",
    "remote_path: str = \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to define what required binaries and JSON annotations to be downloaded for the next parse functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def download_data(dataset: dl.Dataset, remote_path: str, download_path) -> tuple:\n",
    "    \"\"\"\n",
    "    Download the required data for the parser\n",
    "    :param dataset: Input dataset\n",
    "    :param remote_path: Path to the remote folder where the Lidar data is uploaded\n",
    "    :param download_path: Path to the downloaded data\n",
    "    :return: (items_path, json_path) Paths to the downloaded items and annotations JSON files directories\n",
    "    \"\"\"\n",
    "    # Download items dataloop annotation JSONs\n",
    "    # (PCD and Image annotation JSONs contains the Dataloop platform references (Like: ID) to the remote files)\n",
    "    filters = dl.Filters(field=\"metadata.system.mimetype\", values=\"*pcd*\", method=dl.FiltersMethod.OR)\n",
    "    filters.add(field=\"metadata.system.mimetype\", values=\"*image*\", method=dl.FiltersMethod.OR)\n",
    "    dataset.download_annotations(local_path=download_path, filters=filters)\n",
    "\n",
    "    # Download required binaries (Calibrations Data)\n",
    "    # Pandaset Calibration Data is saved in JSON files (Like: poses.json, intrinsics.json, timestamps.json)\n",
    "    filters = dl.Filters(field=\"metadata.system.mimetype\", values=\"*json*\")\n",
    "    dataset.items.download(local_path=download_path, filters=filters)\n",
    "\n",
    "    # Download required binaries (Annotations Data)\n",
    "    # Pandaset Annotations Data is saved in CSV files (Like: 01.csv in cuboids folder)\n",
    "    filters = dl.Filters(field=\"metadata.system.mimetype\", values=\"*csv*\")\n",
    "    dataset.items.download(local_path=download_path, filters=filters)\n",
    "\n",
    "    items_path = os.path.join(download_path, \"items\", remote_path)\n",
    "    json_path = os.path.join(download_path, \"json\", remote_path)\n",
    "    return items_path, json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if remote_path.startswith(\"/\"):\n",
    "    remote_path = remote_path[1:]\n",
    "\n",
    "if remote_path.endswith(\"/\"):\n",
    "    remote_path = remote_path[:-1]\n",
    "\n",
    "download_path = os.path.join(os.getcwd(), dataset.name)\n",
    "\n",
    "items_path, json_path = download_data(\n",
    "    dataset=dataset,\n",
    "    remote_path=remote_path,\n",
    "    download_path=download_path,\n",
    ")\n",
    "print(items_path + \"\\n\" + json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Lidar Data (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to parse the Lidar Sensor data from the downloaded files \n",
    "(Extrinsic and Timestamps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_lidar_data(items_path, json_path) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the Lidar Calibration data to build all the scene LidarPcdData objects\n",
    "    :param items_path: Paths to the downloaded items directory\n",
    "    :param json_path: Paths to the downloaded annotations JSON files directory\n",
    "    :return: lidar_data: Dictionary containing mapping of frame number to LidarPcdData object\n",
    "    \"\"\"\n",
    "    lidar_data = dict()\n",
    "\n",
    "    lidar_json_path = os.path.join(json_path, \"lidar\")\n",
    "    lidar_items_path = os.path.join(items_path, \"lidar\")\n",
    "\n",
    "    # Opening the poses.json file to get the Extrinsic (Translation and Rotation) of the Lidar Scene per frame\n",
    "    poses_json = os.path.join(lidar_items_path, \"poses.json\")\n",
    "    with open(poses_json, 'r') as f:\n",
    "        poses_json_data: list = json.load(f)\n",
    "\n",
    "    # Opening the poses.json file to get the Timestamps of the Lidar Scene per frame\n",
    "    timestamps_json = os.path.join(lidar_items_path, \"timestamps.json\")\n",
    "    with open(timestamps_json, 'r') as f:\n",
    "        timestamps_json_data: list = json.load(f)\n",
    "\n",
    "    # Get all the lidar JSONs sorted by frame number\n",
    "    lidar_jsons = pathlib.Path(lidar_json_path).rglob('*.json')\n",
    "    lidar_jsons = sorted(lidar_jsons, key=lambda x: int(x.stem))\n",
    "\n",
    "    for lidar_frame_idx, lidar_json in enumerate(lidar_jsons):\n",
    "        with open(lidar_json, 'r') as f:\n",
    "            lidar_json_data = json.load(f)\n",
    "\n",
    "        ground_map_id = lidar_json_data.get(\"metadata\", dict()).get(\"user\", dict()).get(\n",
    "            \"lidar_ground_detection\", dict()).get(\"groundMapId\", None)\n",
    "        lidar_translation = extrinsic_calibrations.Translation(\n",
    "            x=poses_json_data[lidar_frame_idx].get(\"position\", dict()).get(\"x\", 0),\n",
    "            y=poses_json_data[lidar_frame_idx].get(\"position\", dict()).get(\"y\", 0),\n",
    "            z=poses_json_data[lidar_frame_idx].get(\"position\", dict()).get(\"z\", 0),\n",
    "        )\n",
    "        lidar_rotation = extrinsic_calibrations.QuaternionRotation(\n",
    "            x=poses_json_data[lidar_frame_idx].get(\"heading\", dict()).get(\"x\", 0),\n",
    "            y=poses_json_data[lidar_frame_idx].get(\"heading\", dict()).get(\"y\", 0),\n",
    "            z=poses_json_data[lidar_frame_idx].get(\"heading\", dict()).get(\"z\", 0),\n",
    "            w=poses_json_data[lidar_frame_idx].get(\"heading\", dict()).get(\"w\", 1)\n",
    "        )\n",
    "        lidar_timestamp = str(timestamps_json_data[lidar_frame_idx])\n",
    "\n",
    "        lidar_pcd_data = images_and_pcds.LidarPcdData(\n",
    "            item_id=lidar_json_data.get(\"id\"),\n",
    "            ground_id=ground_map_id,\n",
    "            remote_path=lidar_json_data.get(\"filename\"),\n",
    "            extrinsic=extrinsic_calibrations.Extrinsic(\n",
    "                rotation=lidar_rotation,\n",
    "                translation=lidar_translation\n",
    "            ),\n",
    "            timestamp=lidar_timestamp\n",
    "        )\n",
    "        lidar_data[lidar_frame_idx] = lidar_pcd_data\n",
    "\n",
    "    return lidar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lidar_data = parse_lidar_data(items_path=items_path, json_path=json_path)\n",
    "# print(lidar_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Cameras Data (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to parse the Cameras data from all the available cameras downloaded files \n",
    "(Intrinsic, Extrinsic, Timestamps and Distortion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_cameras_data(items_path, json_path) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the Cameras Calibration data to build all the scene LidarCameraData and LidarImageData objects\n",
    "    :param items_path: Paths to the downloaded items directory\n",
    "    :param json_path: Paths to the downloaded annotations JSON files directory\n",
    "    :return: lidar_data: Dictionary containing mapping of camera and frame number\n",
    "    to LidarCameraData and LidarImageData objects\n",
    "    \"\"\"\n",
    "    cameras_data = dict()\n",
    "\n",
    "    camera_json_path = os.path.join(json_path, \"camera\")\n",
    "    camera_items_path = os.path.join(items_path, \"camera\")\n",
    "\n",
    "    # Get the list of all the available camera folders, and building the cameras data objects per camera per frame\n",
    "    camera_folders_list = sorted(os.listdir(camera_json_path))\n",
    "    for camera_folder_idx, camera_folder in enumerate(camera_folders_list):\n",
    "        cameras_data[camera_folder] = dict()\n",
    "\n",
    "        camera_folder_json_path = os.path.join(camera_json_path, camera_folder)\n",
    "        camera_folder_items_path = os.path.join(camera_items_path, camera_folder)\n",
    "\n",
    "        # Opening the intrinsics.json file to get the Intrinsics (fx, fy, cx, cy) of the Current Camera per frame\n",
    "        intrinsics_json = os.path.join(camera_folder_items_path, \"intrinsics.json\")\n",
    "        with open(intrinsics_json, 'r') as f:\n",
    "            intrinsics_json_data: dict = json.load(f)\n",
    "\n",
    "        # Opening the poses.json file to get the Extrinsic (Translation and Rotation) of the Current Camera per frame\n",
    "        poses_json = os.path.join(camera_folder_items_path, \"poses.json\")\n",
    "        with open(poses_json, 'r') as f:\n",
    "            poses_json_data: list = json.load(f)\n",
    "\n",
    "        # Opening the poses.json file to get the Timestamps of the Current Camera per frame\n",
    "        timestamps_json = os.path.join(camera_folder_items_path, \"timestamps.json\")\n",
    "        with open(timestamps_json, 'r') as f:\n",
    "            timestamps_json_data: list = json.load(f)\n",
    "\n",
    "        # Get all the camera JSONs sorted by frame number\n",
    "        camera_jsons = pathlib.Path(camera_folder_json_path).rglob('*.json')\n",
    "        camera_jsons = sorted(camera_jsons, key=lambda x: int(x.stem))\n",
    "\n",
    "        for camera_frame_idx, camera_json in enumerate(camera_jsons):\n",
    "            with open(camera_json, 'r') as f:\n",
    "                camera_json_data = json.load(f)\n",
    "\n",
    "            camera_id = f\"{camera_folder}_frame_{camera_frame_idx}\"\n",
    "            camera_intrinsic = camera_calibrations.Intrinsic(\n",
    "                fx=intrinsics_json_data.get(\"fx\", 0),\n",
    "                fy=intrinsics_json_data.get(\"fy\", 0),\n",
    "                cx=intrinsics_json_data.get(\"cx\", 0),\n",
    "                cy=intrinsics_json_data.get(\"cy\", 0)\n",
    "            )\n",
    "            camera_rotation = extrinsic_calibrations.QuaternionRotation(\n",
    "                x=poses_json_data[camera_frame_idx].get(\"heading\", dict()).get(\"x\", 0),\n",
    "                y=poses_json_data[camera_frame_idx].get(\"heading\", dict()).get(\"y\", 0),\n",
    "                z=poses_json_data[camera_frame_idx].get(\"heading\", dict()).get(\"z\", 0),\n",
    "                w=poses_json_data[camera_frame_idx].get(\"heading\", dict()).get(\"w\", 1)\n",
    "            )\n",
    "            camera_translation = extrinsic_calibrations.Translation(\n",
    "                x=poses_json_data[camera_frame_idx].get(\"position\", dict()).get(\"x\", 0),\n",
    "                y=poses_json_data[camera_frame_idx].get(\"position\", dict()).get(\"y\", 0),\n",
    "                z=poses_json_data[camera_frame_idx].get(\"position\", dict()).get(\"z\", 0)\n",
    "            )\n",
    "            camera_distortion = camera_calibrations.Distortion(\n",
    "                k1=0,\n",
    "                k2=0,\n",
    "                k3=0,\n",
    "                p1=0,\n",
    "                p2=0\n",
    "            )\n",
    "            camera_timestamp = str(timestamps_json_data[camera_frame_idx])\n",
    "\n",
    "            lidar_camera_data = camera_calibrations.LidarCameraData(\n",
    "                intrinsic=camera_intrinsic,\n",
    "                extrinsic=extrinsic_calibrations.Extrinsic(\n",
    "                    rotation=camera_rotation,\n",
    "                    translation=camera_translation\n",
    "                ),\n",
    "                channel=camera_json_data.get(\"filename\"),\n",
    "                distortion=camera_distortion,\n",
    "                cam_id=camera_id,\n",
    "            )\n",
    "\n",
    "            lidar_image_data = images_and_pcds.LidarImageData(\n",
    "                item_id=camera_json_data.get(\"id\"),\n",
    "                lidar_camera=lidar_camera_data,\n",
    "                remote_path=camera_json_data.get(\"filename\"),\n",
    "                timestamp=camera_timestamp\n",
    "            )\n",
    "\n",
    "            cameras_data[camera_folder][camera_frame_idx] = {\n",
    "                \"lidar_camera\": lidar_camera_data,\n",
    "                \"lidar_image\": lidar_image_data\n",
    "            }\n",
    "\n",
    "    return cameras_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cameras_data = parse_cameras_data(items_path=items_path, json_path=json_path)\n",
    "# print(cameras_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Lidar Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the `lidar_data` and `cameras_data` togther to build the `frames.json`, a LiDAR video file, with all the point cloud and image files stitched together, where each frame contains the following information:\n",
    "\n",
    "1. `PCD file:` For further information about how a PCD file must look, refer to [Why a new file format?](https://pointclouds.org/documentation/tutorials/pcd_file_format.html#why-a-new-file-format).\n",
    "\n",
    "2. `JPEG/PNG files:` The images of the available cameras for the given frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_lidar_scene(lidar_data: dict, cameras_data: dict):\n",
    "    \"\"\"\n",
    "    Merge the all the object of lidar_data and cameras_data to build the LidarScene object that will be uploaded as\n",
    "    the frames.json item\n",
    "    :return: scene_data: LidarScene data as JSON that will to be uploaded to the dataloop platform as\n",
    "    the frames.json item\n",
    "    \"\"\"\n",
    "    scene = lidar_scene.LidarScene()\n",
    "    frames_number = len(lidar_data)\n",
    "    for frame_number in range(frames_number):\n",
    "        logger.info(f\"Processing PCD data [Frame: {frame_number}]\")\n",
    "        frame_lidar_pcd_data = lidar_data[frame_number]\n",
    "        lidar_frame_images = list()\n",
    "\n",
    "        for camera_idx, (camera_folder, camera_data) in enumerate(cameras_data.items()):\n",
    "            logger.info(f\"Processing Camera data [Frame: {frame_number}, Camera Index: {camera_idx}]\")\n",
    "            frame_lidar_camera_data = camera_data.get(frame_number, dict()).get(\"lidar_camera\", None)\n",
    "            frame_lidar_image_data = camera_data.get(frame_number, dict()).get(\"lidar_image\", None)\n",
    "\n",
    "            if frame_lidar_camera_data is None or frame_lidar_image_data is None:\n",
    "                continue\n",
    "\n",
    "            scene.add_camera(frame_lidar_camera_data)\n",
    "            lidar_frame_images.append(frame_lidar_image_data)\n",
    "\n",
    "        lidar_scene_frame = lidar_frame.LidarSceneFrame(\n",
    "            lidar_frame_pcd=frame_lidar_pcd_data,\n",
    "            lidar_frame_images=lidar_frame_images\n",
    "        )\n",
    "        scene.add_frame(lidar_scene_frame)\n",
    "\n",
    "    scene_data = scene.to_json()\n",
    "    return scene_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "scene_data = build_lidar_scene(lidar_data=lidar_data, cameras_data=cameras_data)\n",
    "\n",
    "frames_item = dataset.items.upload(\n",
    "    remote_name=\"frames.json\",\n",
    "    remote_path=f\"/{remote_path}\",\n",
    "    local_path=json.dumps(scene_data).encode(),\n",
    "    overwrite=True,\n",
    "    item_metadata={\n",
    "        \"system\": {\n",
    "            \"shebang\": {\n",
    "                \"dltype\": \"PCDFrames\"\n",
    "            }\n",
    "        },\n",
    "        \"fps\": 1\n",
    "    }\n",
    ")\n",
    "print(frames_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Annotations (Customizable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to parse the Annotations data from all the downloaded files.\n",
    "Notices:\n",
    "\n",
    "1. It is possible to modify the function to upload 3D annotations to the 3D point cloud files and 2D annotations to the images.\n",
    "\n",
    "2. Annotations uploaded to the separated point cloud and images files will not be visible on the frames.json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_annotations(frames_item: dl.Item, items_path, json_path):\n",
    "    \"\"\"\n",
    "    Parse the annotations data to build and upload the annotations to the frames.json item\n",
    "    :param items_path: Paths to the downloaded items directory\n",
    "    :param json_path: Paths to the downloaded annotations JSON files directory\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # annotations_json_path = os.path.join(json_path, \"annotations\")\n",
    "    annotations_items_path = os.path.join(items_path, \"annotations\")\n",
    "\n",
    "    builder = frames_item.annotations.builder()\n",
    "    frames_json_data = json.loads(s=frames_item.download(save_locally=False).getvalue())\n",
    "\n",
    "    next_object_id = 0\n",
    "    uid_to_object_id_map = dict()\n",
    "    labels = set()\n",
    "\n",
    "    # Parse the cuboid annotations and add them to the annotations builder\n",
    "    cuboids_items_path = os.path.join(annotations_items_path, \"cuboids\")\n",
    "    cuboids_csvs = pathlib.Path(cuboids_items_path).rglob('*.csv')\n",
    "    cuboids_csvs = sorted(cuboids_csvs, key=lambda x: int(x.stem))\n",
    "\n",
    "    for csv_frame_idx, cuboids_csv in enumerate(cuboids_csvs):\n",
    "        # Getting the Lidar Scene Frame Translation and Rotation\n",
    "        frame_pcd_translation = frames_json_data[\"frames\"][csv_frame_idx][\"translation\"]\n",
    "        frame_pcd_translation = np.array(\n",
    "            [frame_pcd_translation[\"x\"], frame_pcd_translation[\"y\"], frame_pcd_translation[\"z\"]]\n",
    "        )\n",
    "        frame_pcd_rotation = frames_json_data[\"frames\"][csv_frame_idx][\"rotation\"]\n",
    "        frame_pcd_rotation = np.array(\n",
    "            [frame_pcd_rotation[\"x\"], frame_pcd_rotation[\"y\"], frame_pcd_rotation[\"z\"], frame_pcd_rotation[\"w\"]]\n",
    "        )\n",
    "\n",
    "        # Opening the current Scene Frame, cuboid annotations CSV file to get the cuboids annotation data\n",
    "        cuboids_csv_data = pd.read_csv(filepath_or_buffer=cuboids_csv)\n",
    "        for _, row_data in cuboids_csv_data.iterrows():\n",
    "            object_id = uid_to_object_id_map.get(row_data[\"uuid\"], None)\n",
    "            if object_id is None:\n",
    "                object_id = next_object_id\n",
    "                uid_to_object_id_map[row_data[\"uuid\"]] = object_id\n",
    "                next_object_id += 1\n",
    "\n",
    "            ann_label = row_data[\"label\"]\n",
    "            ann_position = np.array([row_data[\"position.x\"], row_data[\"position.y\"], row_data[\"position.z\"]])\n",
    "            ann_quaternion = transformations.quaternion_from_euler(*[0, 0, row_data[\"yaw\"]])\n",
    "            ann_scale = np.array([row_data[\"dimensions.x\"], row_data[\"dimensions.y\"], row_data[\"dimensions.z\"]])\n",
    "\n",
    "            # Calculate the transform matrix of the cuboid annotation relatively to the Scene Frame\n",
    "            ann_transform_matrix = transformations.calc_cuboid_scene_transform_matrix(\n",
    "                cuboid_position=ann_position,\n",
    "                cuboid_quaternion=ann_quaternion,\n",
    "                cuboid_scale=ann_scale,\n",
    "                scene_position=frame_pcd_translation,\n",
    "                scene_quaternion=frame_pcd_rotation\n",
    "            )\n",
    "\n",
    "            # Extract the cuboid Translation and Rotation from the transform matrix\n",
    "            ann_position = transformations.translation_vector_from_transform_matrix(\n",
    "                transform_matrix=ann_transform_matrix\n",
    "            )\n",
    "            ann_rotation_matrix = transformations.rotation_matrix_from_transform_matrix(\n",
    "                transform_matrix=ann_transform_matrix\n",
    "            )\n",
    "            ann_rotation = transformations.euler_from_rotation_matrix(rotation_matrix=ann_rotation_matrix)\n",
    "\n",
    "            # Add the cuboid annotation to the annotations builder\n",
    "            annotation_definition = dl.Cube3d(\n",
    "                label=ann_label,\n",
    "                position=ann_position,\n",
    "                scale=ann_scale,\n",
    "                rotation=ann_rotation\n",
    "            )\n",
    "            builder.add(\n",
    "                annotation_definition=annotation_definition,\n",
    "                object_id=object_id,\n",
    "                frame_num=csv_frame_idx\n",
    "            )\n",
    "            labels.add(ann_label)\n",
    "\n",
    "    builder.upload()\n",
    "    frames_item.dataset.update_labels(label_list=list(labels), upsert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "parse_annotations(frames_item=frames_item, items_path=items_path, json_path=json_path)\n",
    "# frames_item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the directory with all the downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(path=download_path, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
